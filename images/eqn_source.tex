% DATA
\begin{align*}
f_\text{lin}(\textbf{X}) &= \textbf{X}\textbf{W}^\intercal \\
\textbf{W} &= \mathbb{R}^{10\times2} \\
\textbf{W}_{ij} &\sim \mathcal{N}(0,1) \\
\textbf{Y} &= f_{\text{lin}}(\textbf{X}) \\
\end{align*}

% PARAMS
\begin{align*}
\textbf{x} &= [0,\ldots,4\pi] \\
\lvert\textbf{x}\rvert &= 100 \\
f(\textbf{x}) &= [x_i \sin(x_i), x_i \cos(x_i)] \\
\textbf{X} &= f(\textbf{x})
\end{align*}

% LEARNING
\begin{align*}
\textbf{Y} &= \textbf{X}\textbf{W}^\intercal \\
\textbf{W}^\prime &= \text{arg}\,\text{min}_\textbf{W}\ \mathcal{L}(\mathbf{W}) \\
\textbf{X}^\prime &= \textbf{Y}\textbf{W}^\prime(\textbf{W}^{\prime\intercal}\textbf{W}^\prime)^{-1} \\
\end{align*}

% OBJECTIVE
\begin{align*}
\mathcal{L}(\textbf{W}) &= \frac{N}{2}\bigg(\overbrace{\Tr\big((\textbf{W}\textbf{W}^T+\sigma^2\textbf{I})^{-1}\textbf{Y}\textbf{Y}^T\big)}^{A} + \overbrace{\log(\lvert\textbf{W}\textbf{W}^T+\sigma^2\textbf{I}\vert)}^{B} + \overbrace{D\log2\pi}^{C}\bigg)
\end{align*}

% DERIVATIVE OF OBJECTIVE
\begin{align*}
\frac{\partial\mathcal{L}}{\partial\textbf{W}_{ij}} =\ &\frac{N}{2}\Bigg(\ \overbrace{\text{Tr}\Big[\textbf{Y}^T\textbf{Y}\big(-(\textbf{W}\textbf{W}^T+\sigma^2\textbf{I})^{-1}(\textbf{J}^{ij}\textbf{W}^T + \textbf{W}\textbf{J}^{ij}^T)(\textbf{W}\textbf{W}^T+\sigma^2\textbf{I})\big)\Big]}^{A} \\ 
	&+ \overbrace{\text{Tr}\Big[(\textbf{W}\textbf{W}^T+\sigma^2\textbf{I})^{-1}(\textbf{J}^{ij}\textbf{W}^T + \textbf{W}\textbf{J}^{ij}^T)\Big]}^{B}\Bigg)
\end{align*}

% ROTATION INVARIANT
\begin{align*}
&\mathcal{N}(y_i|0,(\textbf{W}^\prime\textbf{R})(\textbf{W}^\prime\textbf{R})^T + \sigma^2\textbf{I}) \\
&\mathcal{N}(y_i|0,\textbf{W}^\prime\textbf{R}\textbf{R}^T\textbf{W}^\prime^T + \sigma^2\textbf{I}) \\
&\mathcal{N}(y_i|0,\textbf{W}^\prime\textbf{W}^\prime^T + \sigma^2\textbf{I})
\end{align*}

% LIKELIHOOD
\begin{align*}
p(\textbf{Y}|\textbf{W}) = \prod_{i=1}^N\mathcal{N}(y_i|0,\textbf{W}\textbf{W}^T + \sigma^2\textbf{I})
\end{align*}
